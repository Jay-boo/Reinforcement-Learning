{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://twice22.github.io/rl-part4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay_boo/.local/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/jay_boo/.local/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env=gym.make(\"Blackjack-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple(Discrete(32), Discrete(11), Discrete(2))\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tuples rpresent the states :\n",
    "\n",
    "&rarr;The first element is the current player's sum $ {0,1,....,31 } $\n",
    "\n",
    "&rarr; The second is the dealer's face up card ${1,...,10}$\n",
    "\n",
    "&rarr; The plays has an usuale ace $0,1$. O:NO , 1:YES\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 1, False), {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset(return_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En terme d'action possible : Soit on retire une carte, soit l'on ne fait rien :\n",
    "\n",
    " - 1 : HIT. On tire une carte\n",
    " - 2 : Stick. ON ne tire pas de carte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19, 1, False), 0.0, False, {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let launch 4 parties with random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 9, False)\n",
      "(21, 9, False)\n",
      "lose\n",
      "\n",
      "(7, 8, False)\n",
      "lose\n",
      "\n",
      "(11, 6, False)\n",
      "win\n",
      "(20, 10, False)\n",
      "lose\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(4):\n",
    "    state=env.reset()\n",
    "    while True :\n",
    "        print(state)\n",
    "        a=env.action_space.sample()\n",
    "        state,reward,term,info=env.step(a)\n",
    "        if term :\n",
    "            print(\"win\" if reward >0 else \"lose\"+\"\\n\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode_deterministic(env):\n",
    "    state=env.reset()\n",
    "    episode=[]\n",
    "    while True:\n",
    "        action=int(state[0]<=18)#Our deterministic policy\n",
    "        nextState,reward,term,info=env.step(action)\n",
    "        episode.append((state,action,reward))\n",
    "        state=nextState\n",
    "        if term :\n",
    "            break\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte-Carlo  Value estimation first visit:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCV(env,generate_episode,gamma,episodes):\n",
    "    V,returns={},{}\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        trajectory = generate_episode(env)\n",
    "        G,T=0,len(trajectory)\n",
    "        visited_state=set()\n",
    "\n",
    "        for i in range(T-1,-1,-1):\n",
    "            state,action,reward=trajectory[i]\n",
    "            G+=gamma**i * reward\n",
    "            if state not in visited_state :\n",
    "                reward, visits = returns.get(state,[0,0])\n",
    "                returns[state]= [reward + G ,visits +1]\n",
    "                visited_state.add(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
